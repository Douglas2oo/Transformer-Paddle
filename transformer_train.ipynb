{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据导入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删去中文列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>There are two new old-age insurance benefits f...</td>\n",
       "      <td>Police disprove \"bird's nest congress each per...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP outstrips Hong Kong? Shenzhen S...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>The GDP overtopped Hong Kong? Shenzhen clarifi...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP topped Hong Kong last year? She...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>\"How to discriminate oil from gutter oil by me...</td>\n",
       "      <td>It took 30 years of cooking oil to know that o...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  tid1  tid2                                          title1_en  \\\n",
       "0   0     0     1  There are two new old-age insurance benefits f...   \n",
       "1   3     2     3  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "2   1     2     4  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "3   2     2     5  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "4   9     6     7  \"How to discriminate oil from gutter oil by me...   \n",
       "\n",
       "                                           title2_en      label  \n",
       "0  Police disprove \"bird's nest congress each per...  unrelated  \n",
       "1  Shenzhen's GDP outstrips Hong Kong? Shenzhen S...  unrelated  \n",
       "2  The GDP overtopped Hong Kong? Shenzhen clarifi...  unrelated  \n",
       "3  Shenzhen's GDP topped Hong Kong last year? She...  unrelated  \n",
       "4  It took 30 years of cooking oil to know that o...     agreed  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "\n",
    "del train['title1_zh']\n",
    "del train['title2_zh']\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321187</td>\n",
       "      <td>167562</td>\n",
       "      <td>59521</td>\n",
       "      <td>egypt 's presidential election failed to win m...</td>\n",
       "      <td>Lyon! Lyon officials have denied that Felipe F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321190</td>\n",
       "      <td>167564</td>\n",
       "      <td>91315</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>The Top 10 Americans believe that the Lizard M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321189</td>\n",
       "      <td>167563</td>\n",
       "      <td>167564</td>\n",
       "      <td>Will the United States wage war on Iraq withou...</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321193</td>\n",
       "      <td>167564</td>\n",
       "      <td>160994</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>The hanging Saddam is a surrogate? This man's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321191</td>\n",
       "      <td>167564</td>\n",
       "      <td>15084</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>Chinese loquat loquat plaster in America? Pure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    tid1    tid2                                          title1_en  \\\n",
       "0  321187  167562   59521  egypt 's presidential election failed to win m...   \n",
       "1  321190  167564   91315  A message from Saddam Hussein after he was cap...   \n",
       "2  321189  167563  167564  Will the United States wage war on Iraq withou...   \n",
       "3  321193  167564  160994  A message from Saddam Hussein after he was cap...   \n",
       "4  321191  167564   15084  A message from Saddam Hussein after he was cap...   \n",
       "\n",
       "                                           title2_en  \n",
       "0  Lyon! Lyon officials have denied that Felipe F...  \n",
       "1  The Top 10 Americans believe that the Lizard M...  \n",
       "2  A message from Saddam Hussein after he was cap...  \n",
       "3  The hanging Saddam is a surrogate? This man's ...  \n",
       "4  Chinese loquat loquat plaster in America? Pure...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "del test['title1_zh']\n",
    "del test['title2_zh']\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Expected</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>347448</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>347449</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359100</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359101</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359102</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   Expected  Weight    Usage\n",
       "0  347448  unrelated  0.0625   Public\n",
       "1  347449  unrelated  0.0625  Private\n",
       "2  359100  unrelated  0.0625   Public\n",
       "3  359101  unrelated  0.0625  Private\n",
       "4  359102  unrelated  0.0625  Private"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution = pd.read_csv('./data/solution.csv')\n",
    "\n",
    "solution.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特殊值处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 特殊符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若字符串中全是特殊符号，则删除该行\n",
    "\n",
    "import re\n",
    "\n",
    "def is_special(s, threshold=0.4):\n",
    "    non_alnum_chars = re.findall(r'[^a-zA-Z0-9\\s]', s)\n",
    "    non_alnum_ratio = len(non_alnum_chars) / len(s)\n",
    "    \n",
    "    return non_alnum_ratio > threshold\n",
    "\n",
    "special_1 = train['title1_en'].apply(is_special)\n",
    "special_2 = train['title2_en'].apply(is_special)\n",
    "\n",
    "train = train[~special_1 & ~special_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 重复值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若字符串中有重复10次以上的单词，词组，或是长串连续字符则删除该行\n",
    "\n",
    "def is_repeated(s, min_repeats=6):\n",
    "    char_pattern = r'(.)\\1{' + str(min_repeats - 1) + ',}'\n",
    "    phase_pattern = r'\\b(\\w+\\s?\\w*)\\b(?:\\W+\\1\\b){' + str(min_repeats - 1) + ',}'\n",
    "    word_pattern = r'\\b(\\w+)\\b(?:.*?\\b\\1\\b){' + str(min_repeats - 1) + ',}'\n",
    "    return bool(re.search(r'\\b(\\w+\\s?\\w*)\\b(?:\\W+\\1\\b){' + str(min_repeats) + ',}', s)) or bool(re.search(char_pattern, s)) or bool(re.search(phase_pattern, s)) or bool(re.search(word_pattern, s))\n",
    "\n",
    "repeated_1 = train['title1_en'].apply(is_repeated)\n",
    "repeated_2 = train['title2_en'].apply(is_repeated)\n",
    "\n",
    "train = train[~repeated_1 & ~repeated_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 发现数据中有个别行中存在大量“UNK”，大概是由于使用模型翻译时词典中找不到适配的词汇导致的\n",
    "# 为了防止这些样本对模型训练产生干扰，我们可以将这些样本所在行删除\n",
    "# 样本中出现多于8个“UNK”的行将被删除\n",
    "\n",
    "mask_1 = train['title1_en'].apply(lambda x: x.lower().split().count('unk') > 8)\n",
    "mask_2 = train['title2_en'].apply(lambda x: x.lower().split().count('unk') > 8)\n",
    "\n",
    "# 删除满足条件的行\n",
    "train = train[~mask_1 & ~mask_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and saw a UFO.\n",
      "14\n",
      "1\n",
      "38559    The \"new changes in college entrance examinati...\n",
      "Name: title1_en, dtype: object\n",
      "502\n"
     ]
    }
   ],
   "source": [
    "lengths_1 = train['title1_en'].apply(len)\n",
    "max_1 = lengths_1.max()\n",
    "index1 = lengths_1.idxmax()\n",
    "print(train.iloc[index1]['title1_en'])\n",
    "print(len(train.iloc[index1]['title1_en']))\n",
    "print(len(train[train['id']==index1]['title1_en']))\n",
    "print(train[train['id']==index1]['title1_en'])\n",
    "print(max_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502 After the incident of Gao Yun-cheung's sexual assault scandal broke out, his co-starring with Bing Bing (formerly: Winning the World) was doomed. It had been reported that Tangde wanted to replace the remake, but later on the Tang side denied the cancellation of Gao Yun-xiang's relevant parts. “ A replica of Li Chen ” It's just a technical test. \n",
      "It has been reported that Gao Yun-cheung had previously signed a morality clause with the Ba-Qing Sect, citing the impact of the incident, Gao Yun-cheung\n",
      "Series([], Name: title1_en, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "print(len(train['title1_en'][index1]), train['title1_en'][index1])\n",
    "print(train[train['id']==115330]['title1_en'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本清理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 去除标点符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(x):\n",
    "    x = re.sub(r'[^\\w\\s]','',x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 转成小写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(x):\n",
    "    return x.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# def remove_stopwords(text):\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     return ' '.join([word for word in text.split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 去除多余空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 整合步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = remove_punctuation(text)\n",
    "    text = to_lowercase(text)\n",
    "    # text = remove_stopwords(text)\n",
    "    text = remove_extra_spaces(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>there are two new oldage insurance benefits fo...</td>\n",
       "      <td>police disprove birds nest congress each perso...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>if you do not come to shenzhen sooner or later...</td>\n",
       "      <td>shenzhens gdp outstrips hong kong shenzhen sta...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>if you do not come to shenzhen sooner or later...</td>\n",
       "      <td>shenzhens gdp topped hong kong last year shenz...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>how to discriminate oil from gutter oil by mea...</td>\n",
       "      <td>it took 30 years of cooking oil to know that o...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>if you do not come to shenzhen sooner or later...</td>\n",
       "      <td>shenzhens gdp overtakes hong kong bureau of st...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  tid1  tid2                                          title1_en  \\\n",
       "0   0     0     1  there are two new oldage insurance benefits fo...   \n",
       "1   3     2     3  if you do not come to shenzhen sooner or later...   \n",
       "3   2     2     5  if you do not come to shenzhen sooner or later...   \n",
       "4   9     6     7  how to discriminate oil from gutter oil by mea...   \n",
       "5   4     2     8  if you do not come to shenzhen sooner or later...   \n",
       "\n",
       "                                           title2_en      label  \n",
       "0  police disprove birds nest congress each perso...  unrelated  \n",
       "1  shenzhens gdp outstrips hong kong shenzhen sta...  unrelated  \n",
       "3  shenzhens gdp topped hong kong last year shenz...  unrelated  \n",
       "4  it took 30 years of cooking oil to know that o...     agreed  \n",
       "5  shenzhens gdp overtakes hong kong bureau of st...  unrelated  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['title1_en'] = train['title1_en'].apply(clean_text)\n",
    "train['title2_en'] = train['title2_en'].apply(clean_text)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321187</td>\n",
       "      <td>167562</td>\n",
       "      <td>59521</td>\n",
       "      <td>egypt s presidential election failed to win mi...</td>\n",
       "      <td>lyon lyon officials have denied that felipe fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321190</td>\n",
       "      <td>167564</td>\n",
       "      <td>91315</td>\n",
       "      <td>a message from saddam hussein after he was cap...</td>\n",
       "      <td>the top 10 americans believe that the lizard m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321189</td>\n",
       "      <td>167563</td>\n",
       "      <td>167564</td>\n",
       "      <td>will the united states wage war on iraq withou...</td>\n",
       "      <td>a message from saddam hussein after he was cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321193</td>\n",
       "      <td>167564</td>\n",
       "      <td>160994</td>\n",
       "      <td>a message from saddam hussein after he was cap...</td>\n",
       "      <td>the hanging saddam is a surrogate this mans mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321191</td>\n",
       "      <td>167564</td>\n",
       "      <td>15084</td>\n",
       "      <td>a message from saddam hussein after he was cap...</td>\n",
       "      <td>chinese loquat loquat plaster in america pure ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    tid1    tid2                                          title1_en  \\\n",
       "0  321187  167562   59521  egypt s presidential election failed to win mi...   \n",
       "1  321190  167564   91315  a message from saddam hussein after he was cap...   \n",
       "2  321189  167563  167564  will the united states wage war on iraq withou...   \n",
       "3  321193  167564  160994  a message from saddam hussein after he was cap...   \n",
       "4  321191  167564   15084  a message from saddam hussein after he was cap...   \n",
       "\n",
       "                                           title2_en  \n",
       "0  lyon lyon officials have denied that felipe fe...  \n",
       "1  the top 10 americans believe that the lizard m...  \n",
       "2  a message from saddam hussein after he was cap...  \n",
       "3  the hanging saddam is a surrogate this mans mo...  \n",
       "4  chinese loquat loquat plaster in america pure ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['title1_en'] = test['title1_en'].apply(clean_text)\n",
    "test['title2_en'] = test['title2_en'].apply(clean_text)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标签编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>there are two new oldage insurance benefits fo...</td>\n",
       "      <td>police disprove birds nest congress each perso...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>if you do not come to shenzhen sooner or later...</td>\n",
       "      <td>shenzhens gdp outstrips hong kong shenzhen sta...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>if you do not come to shenzhen sooner or later...</td>\n",
       "      <td>shenzhens gdp topped hong kong last year shenz...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>how to discriminate oil from gutter oil by mea...</td>\n",
       "      <td>it took 30 years of cooking oil to know that o...</td>\n",
       "      <td>agreed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>if you do not come to shenzhen sooner or later...</td>\n",
       "      <td>shenzhens gdp overtakes hong kong bureau of st...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  tid1  tid2                                          title1_en  \\\n",
       "0   0     0     1  there are two new oldage insurance benefits fo...   \n",
       "1   3     2     3  if you do not come to shenzhen sooner or later...   \n",
       "3   2     2     5  if you do not come to shenzhen sooner or later...   \n",
       "4   9     6     7  how to discriminate oil from gutter oil by mea...   \n",
       "5   4     2     8  if you do not come to shenzhen sooner or later...   \n",
       "\n",
       "                                           title2_en      label  label_encoded  \n",
       "0  police disprove birds nest congress each perso...  unrelated              2  \n",
       "1  shenzhens gdp outstrips hong kong shenzhen sta...  unrelated              2  \n",
       "3  shenzhens gdp topped hong kong last year shenz...  unrelated              2  \n",
       "4  it took 30 years of cooking oil to know that o...     agreed              0  \n",
       "5  shenzhens gdp overtakes hong kong bureau of st...  unrelated              2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "'''\n",
    "agreed = 0\n",
    "disagreed = 1\n",
    "unrelated = 2\n",
    "'''\n",
    "\n",
    "# 初始化 LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train['label_encoded'] = label_encoder.fit_transform(train['label'])\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Expected</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>347448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>347449</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359101</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359102</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Expected  Weight    Usage\n",
       "0  347448         2  0.0625   Public\n",
       "1  347449         2  0.0625  Private\n",
       "2  359100         2  0.0625   Public\n",
       "3  359101         2  0.0625  Private\n",
       "4  359102         2  0.0625  Private"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution['Expected'] = label_encoder.fit_transform(solution['Expected'])\n",
    "\n",
    "solution.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本向量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 加载数据集（字典化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'tid1': 0, 'tid2': 1, 'title1_en': 'there are two new oldage insurance benefits for old people in rural areas have you got them', 'title2_en': 'police disprove birds nest congress each person gets 50000 yuan still old people insist on going to beijing', 'label': 'unrelated', 'label_encoded': 2}\n",
      "{'id': 321187, 'tid1': 167562, 'tid2': 59521, 'title1_en': 'egypt s presidential election failed to win millions of votes in egypt s presidential election', 'title2_en': 'lyon lyon officials have denied that felipe federico has joined liverpool is it true that the price has not been agreed'}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AFQMC(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = self.load_data(data_file)\n",
    "    \n",
    "    def load_data(self, data_file):\n",
    "        data_file = data_file.reset_index(drop=True)  # 重置索引\n",
    "        Data = data_file.to_dict(orient='index')\n",
    "        return Data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx not in self.data:\n",
    "            raise KeyError(f\"Key {idx} not found in dataset\")\n",
    "        return self.data[idx]\n",
    "\n",
    "train_dict = AFQMC(train)\n",
    "test_dict = AFQMC(test)\n",
    "\n",
    "print(train_dict[0])\n",
    "print(test_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果数据集非常巨大，难以一次性加载到内存中，我们也可以继承 IterableDataset 类构建迭代型数据集\n",
    "\n",
    "# from torch.utils.data import IterableDataset\n",
    "# import json\n",
    "\n",
    "# class IterableAFQMC(IterableDataset):\n",
    "#     def __init__(self, data_file):\n",
    "#         self.data_file = data_file\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         df = self.data_file\n",
    "#         for _, row in df.iterrows():\n",
    "#             sample = row.to_dict()\n",
    "#             yield sample\n",
    "\n",
    "\n",
    "# try:\n",
    "#     train_dict = IterableAFQMC(train)\n",
    "#     print(next(iter(train_dict)))\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_X shape: {'input_ids': torch.Size([4, 66]), 'token_type_ids': torch.Size([4, 66]), 'attention_mask': torch.Size([4, 66])}\n",
      "batch_y shape: torch.Size([4])\n",
      "{'input_ids': tensor([[  101,  1175,  1132,  1160,  1207,  1385,  2553,  5986,  6245,  1111,\n",
      "          1385,  1234,  1107,  3738,  1877,  1138,  1128,  1400,  1172,   102,\n",
      "          2021,  4267, 20080, 24157,  4939, 10175, 16821,  1296,  1825,  3370,\n",
      "         13837,  1568,   194,  8734,  1253,  1385,  1234, 19831,  1113,  1280,\n",
      "          1106,  1129, 23784,  2118,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1191,  1128,  1202,  1136,  1435,  1106,  1131, 19411, 10436,\n",
      "         10639,  1137,  1224,  1240,  1488,  1209,  1145,  1435,  1107,  1750,\n",
      "          1190,  1275,  1201,  1131, 19411, 10436,  1679,  8008,   176,  1181,\n",
      "          1643,  1209, 13908, 16358,  2118,   180,  4553,   102,  1131, 19411,\n",
      "         10436,  1116,   176,  1181,  1643, 24046, 19091,  3491, 16358,  2118,\n",
      "           180,  4553,  1131, 19411, 10436,  9161, 18561, 21728,  1279, 12287,\n",
      "          1178,  1103,  7275,  1110, 25277,   102],\n",
      "        [  101,  1191,  1128,  1202,  1136,  1435,  1106,  1131, 19411, 10436,\n",
      "         10639,  1137,  1224,  1240,  1488,  1209,  1145,  1435,  1107,  1750,\n",
      "          1190,  1275,  1201,  1131, 19411, 10436,  1679,  8008,   176,  1181,\n",
      "          1643,  1209, 13908, 16358,  2118,   180,  4553,   102,  1131, 19411,\n",
      "         10436,  1116,   176,  1181,  1643,  9065, 16358,  2118,   180,  4553,\n",
      "          1314,  1214,  1131, 19411, 10436, 18561,  1104,  9161,  1231, 14703,\n",
      "          3052, 12287,  5391,  1475,  3775,   102],\n",
      "        [  101,  1293,  1106,  6187, 10205, 14248,  2949,  1121,  9691,  2083,\n",
      "          2949,  1118,  2086,  1104, 24861,   102,  1122,  1261,  1476,  1201,\n",
      "          1104,  8739,  2949,  1106,  1221,  1115,  1141,  2727,  1104, 24861,\n",
      "          1110,  3123,  1106,  3205,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "tensor([2, 2, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "\n",
    "def collote_fn(batch_samples):\n",
    "    try:\n",
    "        batch_sentence_1, batch_sentence_2 = [], []\n",
    "        batch_label = []\n",
    "        # for i in range(len(batch_samples)):\n",
    "        #     batch_sentence_1.append(batch_samples.iloc[i]['title1_en'])\n",
    "        #     batch_sentence_2.append(batch_samples.iloc[i]['title2_en'])\n",
    "        #     batch_label.append(int(batch_samples.iloc[i]['label_encoded']))\n",
    "        for sample in batch_samples:\n",
    "            batch_sentence_1.append(sample['title1_en'])\n",
    "            batch_sentence_2.append(sample['title2_en'])\n",
    "            batch_label.append(int(sample['label_encoded']))\n",
    "        X = tokenizer(\n",
    "            batch_sentence_1, \n",
    "            batch_sentence_2, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        y = torch.tensor(batch_label)\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        print(f\"Error in collote_fn: {e}\")\n",
    "        raise\n",
    "\n",
    "train_dataloader = DataLoader(train_dict, batch_size=4, collate_fn=collote_fn)\n",
    "\n",
    "batch_X, batch_y = next(iter(train_dataloader))\n",
    "print('batch_X shape:', {k: v.shape for k, v in batch_X.items()})\n",
    "print('batch_y shape:', batch_y.shape)\n",
    "print(batch_X)\n",
    "print(batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chineseocr1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
