{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "solution = pd.read_csv('./data/solution.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删去中文列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>There are two new old-age insurance benefits f...</td>\n",
       "      <td>Police disprove \"bird's nest congress each per...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP outstrips Hong Kong? Shenzhen S...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>The GDP overtopped Hong Kong? Shenzhen clarifi...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP topped Hong Kong last year? She...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>\"How to discriminate oil from gutter oil by me...</td>\n",
       "      <td>It took 30 years of cooking oil to know that o...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  tid1  tid2                                          title1_en  \\\n",
       "0   0     0     1  There are two new old-age insurance benefits f...   \n",
       "1   3     2     3  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "2   1     2     4  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "3   2     2     5  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "4   9     6     7  \"How to discriminate oil from gutter oil by me...   \n",
       "\n",
       "                                           title2_en      label  \n",
       "0  Police disprove \"bird's nest congress each per...  unrelated  \n",
       "1  Shenzhen's GDP outstrips Hong Kong? Shenzhen S...  unrelated  \n",
       "2  The GDP overtopped Hong Kong? Shenzhen clarifi...  unrelated  \n",
       "3  Shenzhen's GDP topped Hong Kong last year? She...  unrelated  \n",
       "4  It took 30 years of cooking oil to know that o...     agreed  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train['title1_zh']\n",
    "del train['title2_zh']\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321187</td>\n",
       "      <td>167562</td>\n",
       "      <td>59521</td>\n",
       "      <td>egypt 's presidential election failed to win m...</td>\n",
       "      <td>Lyon! Lyon officials have denied that Felipe F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321190</td>\n",
       "      <td>167564</td>\n",
       "      <td>91315</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>The Top 10 Americans believe that the Lizard M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321189</td>\n",
       "      <td>167563</td>\n",
       "      <td>167564</td>\n",
       "      <td>Will the United States wage war on Iraq withou...</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321193</td>\n",
       "      <td>167564</td>\n",
       "      <td>160994</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>The hanging Saddam is a surrogate? This man's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321191</td>\n",
       "      <td>167564</td>\n",
       "      <td>15084</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>Chinese loquat loquat plaster in America? Pure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    tid1    tid2                                          title1_en  \\\n",
       "0  321187  167562   59521  egypt 's presidential election failed to win m...   \n",
       "1  321190  167564   91315  A message from Saddam Hussein after he was cap...   \n",
       "2  321189  167563  167564  Will the United States wage war on Iraq withou...   \n",
       "3  321193  167564  160994  A message from Saddam Hussein after he was cap...   \n",
       "4  321191  167564   15084  A message from Saddam Hussein after he was cap...   \n",
       "\n",
       "                                           title2_en  \n",
       "0  Lyon! Lyon officials have denied that Felipe F...  \n",
       "1  The Top 10 Americans believe that the Lizard M...  \n",
       "2  A message from Saddam Hussein after he was cap...  \n",
       "3  The hanging Saddam is a surrogate? This man's ...  \n",
       "4  Chinese loquat loquat plaster in America? Pure...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "del test['title1_zh']\n",
    "del test['title2_zh']\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321187</td>\n",
       "      <td>167562</td>\n",
       "      <td>59521</td>\n",
       "      <td>egypt 's presidential election failed to win m...</td>\n",
       "      <td>Lyon! Lyon officials have denied that Felipe F...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321190</td>\n",
       "      <td>167564</td>\n",
       "      <td>91315</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>The Top 10 Americans believe that the Lizard M...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321189</td>\n",
       "      <td>167563</td>\n",
       "      <td>167564</td>\n",
       "      <td>Will the United States wage war on Iraq withou...</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321193</td>\n",
       "      <td>167564</td>\n",
       "      <td>160994</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>The hanging Saddam is a surrogate? This man's ...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321191</td>\n",
       "      <td>167564</td>\n",
       "      <td>15084</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>Chinese loquat loquat plaster in America? Pure...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    tid1    tid2                                          title1_en  \\\n",
       "0  321187  167562   59521  egypt 's presidential election failed to win m...   \n",
       "1  321190  167564   91315  A message from Saddam Hussein after he was cap...   \n",
       "2  321189  167563  167564  Will the United States wage war on Iraq withou...   \n",
       "3  321193  167564  160994  A message from Saddam Hussein after he was cap...   \n",
       "4  321191  167564   15084  A message from Saddam Hussein after he was cap...   \n",
       "\n",
       "                                           title2_en label_encoded  Weight  \\\n",
       "0  Lyon! Lyon officials have denied that Felipe F...     unrelated  0.0625   \n",
       "1  The Top 10 Americans believe that the Lizard M...     unrelated  0.0625   \n",
       "2  A message from Saddam Hussein after he was cap...     unrelated  0.0625   \n",
       "3  The hanging Saddam is a surrogate? This man's ...     unrelated  0.0625   \n",
       "4  Chinese loquat loquat plaster in America? Pure...     unrelated  0.0625   \n",
       "\n",
       "     Usage  \n",
       "0  Private  \n",
       "1   Public  \n",
       "2  Private  \n",
       "3   Public  \n",
       "4   Public  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution.rename(columns={'Id': 'id'}, inplace=True)\n",
    "solution.rename(columns={'Expected': 'label_encoded'}, inplace=True)\n",
    "\n",
    "test_merged = pd.merge(test, solution, on='id')\n",
    "\n",
    "test_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本清理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 特殊符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若字符串中全是特殊符号，则删除该行\n",
    "\n",
    "import re\n",
    "\n",
    "def is_special(s, threshold=0.4):\n",
    "    non_alnum_chars = re.findall(r'[^a-zA-Z0-9\\s]', s)\n",
    "    non_alnum_ratio = len(non_alnum_chars) / len(s)\n",
    "    \n",
    "    return non_alnum_ratio > threshold\n",
    "\n",
    "special_1 = train['title1_en'].apply(is_special)\n",
    "special_2 = train['title2_en'].apply(is_special)\n",
    "train = train[~special_1 & ~special_2]\n",
    "\n",
    "special_1 = test_merged['title1_en'].apply(is_special)\n",
    "special_2 = test_merged['title2_en'].apply(is_special)\n",
    "test_merged = test_merged[~special_1 & ~special_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 重复值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若字符串中有重复10次以上的单词，词组，或是长串连续字符则删除该行\n",
    "\n",
    "def is_repeated(s, min_repeats=6):\n",
    "    char_pattern = r'(.)\\1{' + str(min_repeats - 1) + ',}'\n",
    "    phase_pattern = r'\\b(\\w+\\s?\\w*)\\b(?:\\W+\\1\\b){' + str(min_repeats - 1) + ',}'\n",
    "    word_pattern = r'\\b(\\w+)\\b(?:.*?\\b\\1\\b){' + str(min_repeats - 1) + ',}'\n",
    "    return bool(re.search(r'\\b(\\w+\\s?\\w*)\\b(?:\\W+\\1\\b){' + str(min_repeats) + ',}', s)) or bool(re.search(char_pattern, s)) or bool(re.search(phase_pattern, s)) or bool(re.search(word_pattern, s))\n",
    "\n",
    "repeated_1 = train['title1_en'].apply(is_repeated)\n",
    "repeated_2 = train['title2_en'].apply(is_repeated)\n",
    "train = train[~repeated_1 & ~repeated_2]\n",
    "\n",
    "repeated_1 = test_merged['title1_en'].apply(is_repeated)\n",
    "repeated_2 = test_merged['title2_en'].apply(is_repeated)\n",
    "test_merged = test_merged[~repeated_1 & ~repeated_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 发现数据中有个别行中存在大量“UNK”，大概是由于使用模型翻译时词典中找不到适配的词汇导致的\n",
    "# 为了防止这些样本对模型训练产生干扰，我们可以将这些样本所在行删除\n",
    "# 样本中出现多于8个“UNK”的行将被删除\n",
    "\n",
    "mask_1 = train['title1_en'].apply(lambda x: x.lower().split().count('unk') > 8)\n",
    "mask_2 = train['title2_en'].apply(lambda x: x.lower().split().count('unk') > 8)\n",
    "train = train[~mask_1 & ~mask_2]\n",
    "\n",
    "mask_1 = test_merged['title1_en'].apply(lambda x: x.lower().split().count('unk') > 8)\n",
    "mask_2 = test_merged['title2_en'].apply(lambda x: x.lower().split().count('unk') > 8)\n",
    "test_merged = test_merged[~mask_1 & ~mask_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 去除标点符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(x):\n",
    "    x = re.sub(r'[^\\w\\s]','',x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 转成小写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(x):\n",
    "    return x.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 去除多余空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 整合步骤并应用（步骤4，5，6，7）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>two new oldage insurance benefits old people r...</td>\n",
       "      <td>police disprove birds nest congress person get...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>come shenzhen sooner later son also come less ...</td>\n",
       "      <td>shenzhens gdp outstrips hong kong shenzhen sta...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>come shenzhen sooner later son also come less ...</td>\n",
       "      <td>shenzhens gdp topped hong kong last year shenz...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>discriminate oil gutter oil means garlic</td>\n",
       "      <td>took 30 years cooking oil know one piece garli...</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>come shenzhen sooner later son also come less ...</td>\n",
       "      <td>shenzhens gdp overtakes hong kong bureau stati...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  tid1  tid2                                          title1_en  \\\n",
       "0   0     0     1  two new oldage insurance benefits old people r...   \n",
       "1   3     2     3  come shenzhen sooner later son also come less ...   \n",
       "3   2     2     5  come shenzhen sooner later son also come less ...   \n",
       "4   9     6     7           discriminate oil gutter oil means garlic   \n",
       "5   4     2     8  come shenzhen sooner later son also come less ...   \n",
       "\n",
       "                                           title2_en      label  \n",
       "0  police disprove birds nest congress person get...  unrelated  \n",
       "1  shenzhens gdp outstrips hong kong shenzhen sta...  unrelated  \n",
       "3  shenzhens gdp topped hong kong last year shenz...  unrelated  \n",
       "4  took 30 years cooking oil know one piece garli...     agreed  \n",
       "5  shenzhens gdp overtakes hong kong bureau stati...  unrelated  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = remove_punctuation(text)\n",
    "    text = to_lowercase(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_extra_spaces(text)\n",
    "    return text\n",
    "\n",
    "train['title1_en'] = train['title1_en'].apply(clean_text)\n",
    "train['title2_en'] = train['title2_en'].apply(clean_text)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321187</td>\n",
       "      <td>167562</td>\n",
       "      <td>59521</td>\n",
       "      <td>egypt presidential election failed win million...</td>\n",
       "      <td>lyon lyon officials denied felipe federico joi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321190</td>\n",
       "      <td>167564</td>\n",
       "      <td>91315</td>\n",
       "      <td>message saddam hussein captured</td>\n",
       "      <td>top 10 americans believe lizard man controls u...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321189</td>\n",
       "      <td>167563</td>\n",
       "      <td>167564</td>\n",
       "      <td>united states wage war iraq without destructio...</td>\n",
       "      <td>message saddam hussein captured</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321193</td>\n",
       "      <td>167564</td>\n",
       "      <td>160994</td>\n",
       "      <td>message saddam hussein captured</td>\n",
       "      <td>hanging saddam surrogate mans move destroy dou...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321191</td>\n",
       "      <td>167564</td>\n",
       "      <td>15084</td>\n",
       "      <td>message saddam hussein captured</td>\n",
       "      <td>chinese loquat loquat plaster america pure rumor</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    tid1    tid2                                          title1_en  \\\n",
       "0  321187  167562   59521  egypt presidential election failed win million...   \n",
       "1  321190  167564   91315                    message saddam hussein captured   \n",
       "2  321189  167563  167564  united states wage war iraq without destructio...   \n",
       "3  321193  167564  160994                    message saddam hussein captured   \n",
       "4  321191  167564   15084                    message saddam hussein captured   \n",
       "\n",
       "                                           title2_en label_encoded  Weight  \\\n",
       "0  lyon lyon officials denied felipe federico joi...     unrelated  0.0625   \n",
       "1  top 10 americans believe lizard man controls u...     unrelated  0.0625   \n",
       "2                    message saddam hussein captured     unrelated  0.0625   \n",
       "3  hanging saddam surrogate mans move destroy dou...     unrelated  0.0625   \n",
       "4   chinese loquat loquat plaster america pure rumor     unrelated  0.0625   \n",
       "\n",
       "     Usage  \n",
       "0  Private  \n",
       "1   Public  \n",
       "2  Private  \n",
       "3   Public  \n",
       "4   Public  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merged['title1_en'] = test_merged['title1_en'].apply(clean_text)\n",
    "test_merged['title2_en'] = test_merged['title2_en'].apply(clean_text)\n",
    "\n",
    "test_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标签编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>two new oldage insurance benefits old people r...</td>\n",
       "      <td>police disprove birds nest congress person get...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>come shenzhen sooner later son also come less ...</td>\n",
       "      <td>shenzhens gdp outstrips hong kong shenzhen sta...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>come shenzhen sooner later son also come less ...</td>\n",
       "      <td>shenzhens gdp topped hong kong last year shenz...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>discriminate oil gutter oil means garlic</td>\n",
       "      <td>took 30 years cooking oil know one piece garli...</td>\n",
       "      <td>agreed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>come shenzhen sooner later son also come less ...</td>\n",
       "      <td>shenzhens gdp overtakes hong kong bureau stati...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  tid1  tid2                                          title1_en  \\\n",
       "0   0     0     1  two new oldage insurance benefits old people r...   \n",
       "1   3     2     3  come shenzhen sooner later son also come less ...   \n",
       "3   2     2     5  come shenzhen sooner later son also come less ...   \n",
       "4   9     6     7           discriminate oil gutter oil means garlic   \n",
       "5   4     2     8  come shenzhen sooner later son also come less ...   \n",
       "\n",
       "                                           title2_en      label  label_encoded  \n",
       "0  police disprove birds nest congress person get...  unrelated              2  \n",
       "1  shenzhens gdp outstrips hong kong shenzhen sta...  unrelated              2  \n",
       "3  shenzhens gdp topped hong kong last year shenz...  unrelated              2  \n",
       "4  took 30 years cooking oil know one piece garli...     agreed              0  \n",
       "5  shenzhens gdp overtakes hong kong bureau stati...  unrelated              2  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "'''\n",
    "agreed = 0\n",
    "disagreed = 1\n",
    "unrelated = 2\n",
    "'''\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train['label_encoded'] = label_encoder.fit_transform(train['label'])\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>347448</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>347449</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359101</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359102</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  label_encoded  Weight    Usage\n",
       "0  347448              2  0.0625   Public\n",
       "1  347449              2  0.0625  Private\n",
       "2  359100              2  0.0625   Public\n",
       "3  359101              2  0.0625  Private\n",
       "4  359102              2  0.0625  Private"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution['label_encoded'] = label_encoder.fit_transform(solution['label_encoded'])\n",
    "\n",
    "solution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321187</td>\n",
       "      <td>167562</td>\n",
       "      <td>59521</td>\n",
       "      <td>egypt presidential election failed win million...</td>\n",
       "      <td>lyon lyon officials denied felipe federico joi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321190</td>\n",
       "      <td>167564</td>\n",
       "      <td>91315</td>\n",
       "      <td>message saddam hussein captured</td>\n",
       "      <td>top 10 americans believe lizard man controls u...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321189</td>\n",
       "      <td>167563</td>\n",
       "      <td>167564</td>\n",
       "      <td>united states wage war iraq without destructio...</td>\n",
       "      <td>message saddam hussein captured</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321193</td>\n",
       "      <td>167564</td>\n",
       "      <td>160994</td>\n",
       "      <td>message saddam hussein captured</td>\n",
       "      <td>hanging saddam surrogate mans move destroy dou...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321191</td>\n",
       "      <td>167564</td>\n",
       "      <td>15084</td>\n",
       "      <td>message saddam hussein captured</td>\n",
       "      <td>chinese loquat loquat plaster america pure rumor</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    tid1    tid2                                          title1_en  \\\n",
       "0  321187  167562   59521  egypt presidential election failed win million...   \n",
       "1  321190  167564   91315                    message saddam hussein captured   \n",
       "2  321189  167563  167564  united states wage war iraq without destructio...   \n",
       "3  321193  167564  160994                    message saddam hussein captured   \n",
       "4  321191  167564   15084                    message saddam hussein captured   \n",
       "\n",
       "                                           title2_en  label_encoded  Weight  \\\n",
       "0  lyon lyon officials denied felipe federico joi...              2  0.0625   \n",
       "1  top 10 americans believe lizard man controls u...              2  0.0625   \n",
       "2                    message saddam hussein captured              2  0.0625   \n",
       "3  hanging saddam surrogate mans move destroy dou...              2  0.0625   \n",
       "4   chinese loquat loquat plaster america pure rumor              2  0.0625   \n",
       "\n",
       "     Usage  \n",
       "0  Private  \n",
       "1   Public  \n",
       "2  Private  \n",
       "3   Public  \n",
       "4   Public  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merged['label_encoded'] = label_encoder.fit_transform(test_merged['label_encoded'])\n",
    "\n",
    "test_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 已预处理数据导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./data/train_cleaned.csv', index=False)\n",
    "test_merged.to_csv('./data/test_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 已预处理数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_total = pd.read_csv('./data/train_cleaned.csv')\n",
    "test_merged_total = pd.read_csv('./data/test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机抽样缩小原数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_total.sample(frac=0.1, random_state=42).reset_index(drop=True)\n",
    "test_merged = test_merged_total.sample(frac=0.1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本向量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据集（字典化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 275485, 'tid1': 153996, 'tid2': 154013, 'title1_en': 'longer white hair grows dont dye wash washing make hair look black shiny 3 days', 'title2_en': 'yaos exhusband ling soosus high profile comeback revealed reasons divorce', 'label': 'unrelated', 'label_encoded': 2}\n",
      "{'id': 379653, 'tid1': 186512, 'tid2': 186513, 'title1_en': 'ship hit meteor rock crashed another world astronauts kept pets aliens', 'title2_en': 'alien ship crashed ancient vikings fell knees thought god coming', 'label_encoded': 2, 'Weight': 0.0625, 'Usage': 'Private'}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AFQMC(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = self.load_data(data_file)\n",
    "    \n",
    "    def load_data(self, data_file):\n",
    "        data_file = data_file.reset_index(drop=True)\n",
    "        Data = data_file.to_dict(orient='index')\n",
    "        return Data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx not in self.data:\n",
    "            raise KeyError(f\"Key {idx} not found in dataset\")\n",
    "        return self.data[idx]\n",
    "\n",
    "train_dict = AFQMC(train)\n",
    "test_merged_dict = AFQMC(test_merged)\n",
    "\n",
    "print(train_dict[0])\n",
    "print(test_merged_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果数据集非常巨大，难以一次性加载到内存中，我们也可以继承 IterableDataset 类构建迭代型数据集\n",
    "\n",
    "# from torch.utils.data import IterableDataset\n",
    "# import json\n",
    "\n",
    "# class IterableAFQMC(IterableDataset):\n",
    "#     def __init__(self, data_file):\n",
    "#         self.data_file = data_file\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         df = self.data_file\n",
    "#         for _, row in df.iterrows():\n",
    "#             sample = row.to_dict()\n",
    "#             yield sample\n",
    "\n",
    "\n",
    "# try:\n",
    "#     train_dict = IterableAFQMC(traNin)\n",
    "#     print(next(iter(train_dict)))\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_X shape: {'input_ids': torch.Size([2, 37]), 'token_type_ids': torch.Size([2, 37]), 'attention_mask': torch.Size([2, 37])}\n",
      "batch_y shape: torch.Size([2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"google-bert/bert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def collote_fn(batch_samples):\n",
    "    try:\n",
    "        batch_sentence_1, batch_sentence_2 = [], []\n",
    "        batch_label = []\n",
    "        batch_weights = []\n",
    "        for sample in batch_samples:\n",
    "            batch_sentence_1.append(sample['title1_en'])\n",
    "            batch_sentence_2.append(sample['title2_en'])\n",
    "            batch_label.append(int(sample['label_encoded']))\n",
    "            if 'Weight' in sample:\n",
    "                batch_weights.append(float(sample['Weight']))\n",
    "            else:\n",
    "                batch_weights.append(1.0)\n",
    "\n",
    "        X = tokenizer(\n",
    "            batch_sentence_1, \n",
    "            batch_sentence_2, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        y = torch.tensor(batch_label)\n",
    "        w = torch.tensor(batch_weights)\n",
    "\n",
    "        if 'Weight' in sample:\n",
    "            return X, y, w\n",
    "        else:\n",
    "            return X, y\n",
    "    except Exception as e:\n",
    "        print(f\"Error in collote_fn: {e}\")\n",
    "        raise\n",
    "\n",
    "train_dataloader = DataLoader(train_dict, batch_size=2, shuffle=True, collate_fn=collote_fn)\n",
    "valid_dataloader= DataLoader(test_merged_dict, batch_size=2, shuffle=True, collate_fn=collote_fn)\n",
    "\n",
    "\n",
    "batch_X, batch_y = next(iter(train_dataloader))\n",
    "print('batch_X shape:', {k: v.shape for k, v in batch_X.items()})\n",
    "print('batch_y shape:', batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_X shape: {'input_ids': torch.Size([2, 48]), 'token_type_ids': torch.Size([2, 48]), 'attention_mask': torch.Size([2, 48])}\n",
      "batch_y shape: torch.Size([2])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "batch_X1, batch_y1, batch_w1 = next(iter(valid_dataloader))\n",
    "print('batch_X shape:', {k: v.shape for k, v in batch_X1.items()})\n",
    "print('batch_y shape:', batch_y1.shape)\n",
    "print(batch_w1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "TransformerClassifier(\n",
      "  (embedding): Embedding(30000, 512)\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "print(f'Using {device} device')\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, nhead, num_encoder_layers, dim_feedforward, num_classes):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, dim_feedforward)\n",
    "        self.transformer = Transformer(\n",
    "            d_model=dim_feedforward,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=6,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            activation='relu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(dim_feedforward, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src_tensor = src['input_ids']\n",
    "        embedded = self.embedding(src_tensor)\n",
    "        transformer_output = self.transformer(embedded, embedded)\n",
    "        pooled_output = transformer_output.mean(dim=1)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(dropout_output)\n",
    "        return logits\n",
    "\n",
    "input_dim = 30000  \n",
    "nhead = 8\n",
    "num_encoder_layers = 6\n",
    "dim_feedforward = 512\n",
    "num_classes = 3  # 3 classes: agreed, disagreed, unrelated\n",
    "\n",
    "model = TransformerClassifier(input_dim, nhead, num_encoder_layers, dim_feedforward, num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# inputs = {key: value.to(device) for key, value in batch_X.items()}\n",
    "# outputs = model(inputs)  # 使用GPU时统一设备\n",
    "\n",
    "outputs = model(batch_X)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练步骤数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158190\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, no_deprecation_warning=True)\n",
    "epochs = 10\n",
    "num_training_steps = epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练，测试准备\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, lr_scheduler, epoch, total_loss):\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_step_num = (epoch-1)*len(dataloader)\n",
    "    \n",
    "    model.train()\n",
    "    for step, (X, y) in enumerate(dataloader, start=1):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_description(f'loss: {total_loss/(finish_step_num + step):>7f}')\n",
    "        progress_bar.update(1)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test_loop(dataloader, model, mode='Valid'):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_sample_weights = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            try:\n",
    "                inputs = batch[0].to(device)\n",
    "                labels = batch[1].to(device)\n",
    "                sample_weights = batch[2].to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss_fn = nn.CrossEntropyLoss()\n",
    "                loss = loss_fn(outputs, labels)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                all_predictions.append(outputs.argmax(dim=1).cpu().numpy())\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "                all_sample_weights.append(sample_weights.cpu().numpy())\n",
    "            except Exception as e:\n",
    "                print(\"Error encountered:\", e)\n",
    "                print(\"Problematic batch:\", batch)\n",
    "                break                                 \n",
    "\n",
    "    all_predictions = np.concatenate(all_predictions)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_sample_weights = np.concatenate(all_sample_weights)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    return avg_loss, all_predictions, all_labels, all_sample_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加权准确率函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_categorization_accuracy(predictions, labels, sample_weights):\n",
    "    correct_predictions = (predictions == labels).astype(int)\n",
    "    weighted_correct_predictions = correct_predictions * sample_weights\n",
    "    \n",
    "    weighted_accuracy = np.sum(weighted_correct_predictions) / np.sum(sample_weights)\n",
    "    \n",
    "    return weighted_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入原最佳模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerClassifier(\n",
       "  (embedding): Embedding(30000, 512)\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'./transformer_weights/epoch_3_valid_acc_64.3_transformer_weights.bin'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5923102a6844ac93ccdaa023aa093f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Categorization Accuracy: 63.63%\n",
      "Validation Loss: 0.614431\n",
      "saving new weights...\n",
      "\n",
      "Epoch 2/7\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cc8059222d490fb8402127f35ff60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Categorization Accuracy: 64.72%\n",
      "Validation Loss: 0.619105\n",
      "saving new weights...\n",
      "\n",
      "Epoch 3/7\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4bc5481cfa14cebb2bd8d6addc58807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Categorization Accuracy: 68.87%\n",
      "Validation Loss: 0.594560\n",
      "saving new weights...\n",
      "\n",
      "Epoch 4/7\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d34db46d15549ba8b6a2692902c8b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Categorization Accuracy: 68.13%\n",
      "Validation Loss: 0.668118\n",
      "Epoch 5/7\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb982484e2204916bd3ad38524cf4578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Categorization Accuracy: 66.69%\n",
      "Validation Loss: 0.818699\n",
      "Early stopping!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "learning_rate = 1e-5\n",
    "epoch_num = 7\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=epoch_num*len(train_dataloader),\n",
    ")\n",
    "\n",
    "total_loss = 0.\n",
    "patience = 2\n",
    "trigger_times = 0\n",
    "best_acc = 0.\n",
    "best_loss = float(\"inf\")\n",
    "try:\n",
    "    for t in range(epoch_num):\n",
    "        print(f\"Epoch {t+1}/{epoch_num}\\n-------------------------------\")\n",
    "        total_loss = train_loop(train_dataloader, model, loss_fn, optimizer, lr_scheduler, t+1, total_loss)\n",
    "\n",
    "        val_loss, val_predictions, val_labels, val_sample_weights = test_loop(valid_dataloader, model, mode='Valid')\n",
    "\n",
    "        valid_acc = weighted_categorization_accuracy(val_predictions, val_labels, val_sample_weights)\n",
    "        print(f\"Weighted Categorization Accuracy: {(100*valid_acc):0.2f}%\")\n",
    "        print(f\"Validation Loss: {val_loss:>7f}\")\n",
    "\n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = valid_acc\n",
    "            print('saving new weights...\\n')\n",
    "            torch.save(model.state_dict(), f'./transformer_weights/epoch_{t+1}_valid_acc_{(100*valid_acc):0.1f}_transformer_weights.bin')\n",
    "            model.load_state_dict(torch.load(f'./transformer_weights/epoch_{t+1}_valid_acc_{(100*valid_acc):0.1f}_transformer_weights.bin'))\n",
    "\n",
    "            \n",
    "        #早停（如果在某个epoch中模型在验证集上的性能不再提升，可以提前停止训练）\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "\n",
    "        if trigger_times >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "except Exception as e:\n",
    "    print(f\"Error encountered: {e}\")\n",
    "    torch.save(model.state_dict(), './transformer_weights/transformer_weights_on_error.bin')\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加权得分计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Categorization Accuracy: 66.94%\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_predictions, val_labels, val_sample_weights = test_loop(valid_dataloader, model, mode='Test')\n",
    "\n",
    "valid_acc = weighted_categorization_accuracy(val_predictions, val_labels, val_sample_weights)\n",
    "\n",
    "print(f\"Weighted Categorization Accuracy: {(100*valid_acc):0.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
